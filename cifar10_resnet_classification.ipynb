{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet CIFAR-10 图像分类实战\n",
    "\n",
    "本笔记本展示如何使用 **PyTorch** 和 **ResNet-18** 模型对 **CIFAR-10** 数据集进行图像分类。\n",
    "最后我们将使用 **Seaborn** 绘制训练过程中的损失（Loss）和准确率（Accuracy）曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 配置 Seaborn 绘图风格\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "# 自动选择设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"当前使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据准备与预处理\n",
    "\n",
    "这里我们定义数据增强策略（随机裁剪、水平翻转）以提高模型泛化能力，并进行标准化处理。\n",
    "数据集将自动下载到 `./data` 目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数配置\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# 训练集：增强 + 归一化\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 测试集：仅归一化\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 加载数据\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建 ResNet 模型\n",
    "\n",
    "使用 `torchvision.models` 提供的 `resnet18`。由于 CIFAR-10 只有 10 个类别，我们需要修改全连接层（FC Layer）。\n",
    "我们使用预训练参数（`pretrained=True`）来加速收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# 修改输出层为 10 类\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 优化器与损失函数\n",
    "\n",
    "使用交叉熵损失 (`CrossEntropyLoss`) 和 SGD 优化器。配合学习率调度器 (`StepLR`) 在训练后期降低学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 训练与评估循环\n",
    "\n",
    "定义训练和测试函数，记录每个 Epoch 的 Loss 和 Accuracy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = [], []\n",
    "train_accs, test_accs = [], []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "    epoch_loss = running_loss / len(testloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    test_losses.append(epoch_loss)\n",
    "    test_accs.append(epoch_acc)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"开始训练 {EPOCHS} 个 Epochs...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t_loss, t_acc = train(epoch)\n",
    "    v_loss, v_acc = test(epoch)\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1:02d} | Train Loss: {t_loss:.4f} Acc: {t_acc:.2f}% | Test Loss: {v_loss:.4f} Acc: {v_acc:.2f}%\")\n",
    "\n",
    "print(f\"训练完成，总耗时: {(time.time() - start_time)/60:.2f} 分钟\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 可视化训练结果\n",
    "\n",
    "利用 **Seaborn** 绘制 Loss 和 Accuracy 随 Epoch 变化的曲线，直观评估模型效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, EPOCHS + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# 绘制 Loss 曲线\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(x=epochs_range, y=train_losses, label='Train Loss', marker='o')\n",
    "sns.lineplot(x=epochs_range, y=test_losses, label='Test Loss', marker='o')\n",
    "plt.title('Training & Test Loss', fontsize=15)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制 Accuracy 曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(x=epochs_range, y=train_accs, label='Train Acc', marker='o')\n",
    "sns.lineplot(x=epochs_range, y=test_accs, label='Test Acc', marker='o')\n",
    "plt.title('Training & Test Accuracy', fontsize=15)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
