<div align="center" style="font-size: 1.4em; font-weight: bold;">
å®éªŒä¸ƒã€ResNet
</div>
<div style="display: flex; width: 100%; font-size: 1em;">
  <div style="flex: 1; text-align: left;">
    å§“åï¼šå¢è±ªè±ª
  </div>
  <div style="flex: 1; text-align: center;">
    å­¦å·ï¼š202310310239
  </div>
  <div style="flex: 1; text-align: right;">
    æŒ‡å¯¼è€å¸ˆï¼šèƒ¡æ”¿ä¼Ÿ
  </div>
</div>
<hr/>

### ä¸€ã€å®éªŒç›®çš„
PyTorch å®ç° ResNet-18 Model å¯¹ CIFAR-10 æ•°æ®é›†è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚

### äºŒã€å®éªŒå†…å®¹
#### 1ã€dataset
å®éªŒæ•°æ®é›†åˆçš„è¯å°±æ˜¯ä» `torchvision.datasets` å¯¼å…¥çš„å¸¸ç”¨çš„ CIFAR-10 datasetã€‚æ ·æœ¬ç¤ºä¾‹å¦‚ä¸‹ï¼š

![cifar-10](photos/cifar_samples.png)


#### 2ã€Data Augmentation

ä½¿ç”¨ transforms è¿›è¡Œäº†ä¸€äº›å¸¸è§çš„å¢å¼ºæ–¹å¼ï¼Œå¯¹è®­ç»ƒé›†çš„å¤„ç†ï¼ˆæµ‹è¯•é›†åªå½’ä¸€åŒ–ï¼‰åŒ…æ‹¬ï¼š
- padding & RandomCropï¼›
- éšæœºæ°´å¹³ç¿»è½¬ RandomHorizontalFlip()ï¼›
- å½’ä¸€åŒ–ã€‚

```python
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # å¸¸ç”¨çš„å½’ä¸€åŒ–è®¾å®š
])

# Test åª Norm
transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
])
```

#### 3ã€ResNet
è¿™é‡Œçš„è¯å°±ç›´æ¥åˆ©ç”¨äº† `torchvision.models` æä¾›çš„é¢„è®­ç»ƒçš„ `resnet18`ã€‚æ²¡æœ‰ `requires_grad = False` è¿™æ ·å†»ç»“
å‰é¢çš„ä¸€äº›å±‚ï¼Œç›´æ¥å°±æ˜¯å…¨é‡å¾®è°ƒã€‚ç”¨äº† DropOut ï¼Œ`nn.Dropout` è®­ç»ƒå¼€å¯ï¼Œæµ‹è¯•æ—¶å…¶è‡ªåŠ¨å…³é—­ã€‚

```python
model = torchvision.models.resnet18(pretrained=True)

# 10 Cls
num_ftrs = model.fc.in_features
model.fc = nn.Sequential(nn.Dropout(0.5), nn.Linear(num_ftrs, 10))

model = model.to(device)
```

#### 4ã€è®­ç»ƒ
- Optimizer å°±æ˜¯ **SGD With Momentum**ï¼Œç„¶åå¤šæ­¥è¡°å‡ï¼Œ15 ä¸ª epochã€‚

```python
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=5e-4)
scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[7, 12], gamma=0.1)
```
- æµ‹è¯•åŠè¯„ä¼°å®ç°å¦‚ä¸‹ï¼Œä¸å†ç‰¹æ„è¯´æ˜ã€‚
```python
train_losses, test_losses = [], []
train_accs, test_accs = [], []

def train(epoch):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for inputs, labels in trainloader:
        inputs, labels = inputs.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
    
    epoch_loss = running_loss / len(trainloader)
    epoch_acc = 100. * correct / total
    train_losses.append(epoch_loss)
    train_accs.append(epoch_acc)
    return epoch_loss, epoch_acc

def test(epoch):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for inputs, labels in testloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
            
    epoch_loss = running_loss / len(testloader)
    epoch_acc = 100. * correct / total
    test_losses.append(epoch_loss)
    test_accs.append(epoch_acc)
    return epoch_loss, epoch_acc
```

#### 5ã€Visulization
æœ€å Seaborn é£æ ¼ç»˜å›¾ï¼ˆæŒºå–œæ¬¢è¿™ä¸ªé£æ ¼ï¼Œå¸¸ç”¨è¿™ä¸ªğŸ˜ï¼‰ï¼Œå¦‚ä¸‹ï¼š
![result](photos/1.png)


### ä¸‰ã€å®éªŒæ€»ç»“
1. åœ¨å¤šæ¬¡è¿è¡Œæ—¶æˆ‘å‘ç°ï¼Œåœ¨ç¬¬ä¸€æ¬¡è¡°å‡åï¼ŒTrain & Test çš„å‡†ç¡®ç‡å·®è·æ€»æ˜¯ä¼šè¿›ä¸€æ­¥å¢å¤§ï¼›
2. èµ·åˆæˆ‘è®¤ä¸ºæ˜¯è¿‡æ‹Ÿåˆï¼Œä½†æ˜¯åŠ å¼ºæ­£åˆ™åŒ–è¿™ç§è¡°å‡å Gap æ‹‰å¤§æ€»æ˜¯ä¼šå‘ç”Ÿï¼Œä½†æ˜¯å…¶å® Test è¡¨ç°ç¡®ä¹Ÿå§‹ç»ˆæ²¡æœ‰å˜å·®ã€‚æ­¤å¤–å°±æ˜¯å‰æœŸç”šè‡³ Test æ•ˆæœåè€Œä¼˜äº Trainã€‚
3. æ‰€ä»¥ï¼Œç»“åˆä¸Šè¿°ï¼Œæˆ‘çš„ä¸ªäººç†è§£æ˜¯å¯èƒ½ä¸ï¼šDropout ä¸ Data Augmentation æœ‰å…³ï¼ˆä¸è¿‡æš‚æœªè¿›ä¸€æ­¥å®éªŒéªŒè¯ï¼‰ï¼š
   1. å› ä¸ºæˆ‘ DropOut Ratio è®¾ç½®çš„ä¸º 0.5 è¿˜æ˜¯æ¯”è¾ƒå¤§çš„ï¼Œç„¶åè®­ç»ƒæ‰“å¼€éªŒè¯å…³é—­ï¼Œè¿™åº”è¯¥èƒ½è§£é‡Šä¸ºä½•å‰æœŸ Test æ•ˆæœæ›´å¥½ï¼›
   2. å­¦ä¹ ç‡è¡°å‡ï¼ŒModel é€æ¸â€œå…‹æœâ€äº†è®­ç»ƒæ—¶çš„â€œéšæœºå™ªå£°â€œâ€ï¼Œå¯¼è‡´ Train Acc æœ€ç»ˆåè¶…å¹¶æ‹‰å¼€å·®è·ã€‚
